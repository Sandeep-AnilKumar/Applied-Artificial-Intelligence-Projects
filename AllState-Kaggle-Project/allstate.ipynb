{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gBR\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the training data and encoding the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for encoding training data is := 37.85\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "for i in range(1, 117):\n",
    "    train_data['cat' + str(i)] = train_data['cat' + str(i)].astype('category')\n",
    "\n",
    "categorical_columns = train_data.select_dtypes(['category']).columns\n",
    "train_data[categorical_columns] = train_data[categorical_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "print(\"Time for encoding training data is := %.2f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the training data into training subset and test subset, and extracting the vectors and targets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for reading test and train vectors and targets from the subset in the training data is := 0.85\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_data_df, test_data_df = train_test_split(train_data, test_size=0.1)\n",
    "train_data_vector = train_data_df.iloc[:, 1:131]\n",
    "test_data_vector = test_data_df.iloc[:, 1:131]\n",
    "test_data_ids = list(test_data_df['id'])\n",
    "\n",
    "train_data_target = train_data_df.iloc[:, 131]\n",
    "test_data_target = test_data_df.iloc[:, 131]\n",
    "print(\"Time for reading test and train vectors and targets from the subset in the training data is := %.2f\"\n",
    "      % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using xgboost XGBRegressor to train the data and predict loss values on the test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for the regressor to train and predict on the training data subset is := 613.86\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "reg = xgboost.XGBRegressor(reg_alpha=0.2, n_estimators=1000, learning_rate=0.2)\n",
    "reg = reg.fit(train_data_vector, train_data_target)\n",
    "\n",
    "lr_predict = reg.predict(test_data_vector)\n",
    "lr_accuracy = metrics.mean_absolute_error(test_data_target, lr_predict)\n",
    "print(\"Time for the regressor to train and predict on the training data subset is := %.2f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing the id and loss values to a csv file, last line of which contains the \"MAE\" value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = open(\"output_file.csv\", 'w', newline='')\n",
    "wr = csv.writer(csv_file, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "wr.writerow(['id', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with calculating the MAE for the subset of training data\n"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(test_data_ids)):\n",
    "    wr.writerow([test_data_ids[index], lr_predict[index]])\n",
    "    index += 1\n",
    "wr.writerow([\"MAE\", lr_accuracy])\n",
    "print(\"done with calculating the MAE for the subset of training data\")\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the test data from the test.csv which will be used now to predict the loss values. As above, the test data is to encoded for categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for encoding testing data is := 30.46\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "for i in range(1, 117):\n",
    "    test_data['cat' + str(i)] = test_data['cat' + str(i)].astype('category')\n",
    "\n",
    "categorical_columns = test_data.select_dtypes(['category']).columns\n",
    "test_data[categorical_columns] = test_data[categorical_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "print(\"Time for encoding testing data is := %.2f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using xgboost XGBRegressor to train the data and predict loss values on the test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for the regressor to train and predict is := 650.18\n"
     ]
    }
   ],
   "source": [
    "test_data_vector = test_data.iloc[:, 1:131]\n",
    "test_data_ids = list(test_data['id'])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "reg = xgboost.XGBRegressor(reg_alpha=0.2, n_estimators=1000, learning_rate=0.2)\n",
    "reg = reg.fit(train_data_vector, train_data_target)\n",
    "\n",
    "lr_predict = reg.predict(test_data_vector)\n",
    "print(\"Time for the regressor to train and predict is := %.2f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrinting the is and loss values to submissions.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = open(\"submissions.csv\", 'w', newline='')\n",
    "wr = csv.writer(csv_file, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "wr.writerow(['id', 'loss'])\n",
    "\n",
    "for index in range(0, len(test_data_ids)):\n",
    "    wr.writerow([test_data_ids[index], lr_predict[index]])\n",
    "    index += 1\n",
    "print(\"done with predicting loss values for the test data\")\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}